{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57feed3f-800f-47e2-a331-a278221ca27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a707a09e-cf18-4f32-b42a-e36689e946c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_metrics_filename(filename):    \n",
    "    name_parts = filename.split(\"_\")\n",
    "    \n",
    "    # Model size\n",
    "    model_sizes = [\"gpt2-large\", \"gpt2-medium\", \"gpt2-xl\", \"gpt2\"]\n",
    "    model_size = None\n",
    "    for size in model_sizes:\n",
    "        if size in filename:\n",
    "            model_size = size\n",
    "            break\n",
    "            \n",
    "    if \"not_finetuned\" in filename:\n",
    "        return (model_size, None, None, None, None)\n",
    "            \n",
    "    if model_size is None:\n",
    "        print(f\"Cannot find model size in {filename}\")\n",
    "        return\n",
    "    \n",
    "    # Learning rate\n",
    "    lr = None\n",
    "    if \"lr\" in filename:\n",
    "        for part in name_parts:\n",
    "            if \"lr\" in part:\n",
    "                lr = float(part[2:])\n",
    "    else:\n",
    "        for part in name_parts:\n",
    "            if \"e-\" in part:\n",
    "                lr = float(part)\n",
    "    \n",
    "    if lr is None:\n",
    "        print(f\"Cannot find learning rate in {filename}\")\n",
    "        return\n",
    "    \n",
    "    # Unfrozen block\n",
    "    blk = None\n",
    "    if \"blk\" in filename:\n",
    "        for part in name_parts:\n",
    "            if \"blk\" in part:\n",
    "                blk = float(part[3:])\n",
    "    else:\n",
    "        blk = 1.0\n",
    "        \n",
    "    # Check if head is frozen\n",
    "    head_frozen = False\n",
    "    if blk < 1.0:\n",
    "        head_frozen = \"without_head\" in filename\n",
    "        \n",
    "    # Epoch\n",
    "    epoch = None\n",
    "    if \"checkpoint\" in filename:\n",
    "        for part in name_parts:\n",
    "            if \"checkpoint\" in part:\n",
    "                epoch = int(int(part[10:].split(\".\")[0])/5888)\n",
    "    elif \"epoch\" in filename:\n",
    "        epoch = int(name_parts[-1].split(\".\")[0])\n",
    "    \n",
    "    if epoch is None:\n",
    "        print(f\"Cannot find epoch in {filename}\")\n",
    "        return\n",
    "    \n",
    "    return (model_size, lr, blk, epoch, head_frozen)\n",
    "\n",
    "def process_file(filename, force=False):\n",
    "    if not force:\n",
    "        for decode in [\"top-p\", \"temperature\", \"beam_search\"]:\n",
    "            if decode in filename:\n",
    "                return\n",
    "        \n",
    "    res = parse_metrics_filename(filename)\n",
    "    if res is None:\n",
    "        return None\n",
    "        \n",
    "    model_size, lr, blk, epoch, head_frozen = res\n",
    "    df = pd.read_csv(f\"{metrics_path}/{filename}\")\n",
    "    \n",
    "    similarity_score_stats = dict(df[\"similarity_score\"].describe().drop([\"count\",  \"max\"]))\n",
    "    exact_match_stats = dict(df[\"exact_match\"].describe().drop([\"count\", \"min\", \"25%\", \"50%\", \"75%\"]))\n",
    "    \n",
    "    exact_match_count = dict(df[\"exact_match\"].value_counts().drop(0).sort_index(ascending=False).cumsum()[::-1])\n",
    "    exact_match_count[0] = len(df.index) - exact_match_count[1]\n",
    "    \n",
    "    similarity_score_stats = {f'{k}_similarity_score': v for k, v in similarity_score_stats.items()}\n",
    "    exact_match_stats = {f'{k}_exact_match': v for k, v in exact_match_stats.items()}\n",
    "    exact_match_count = {f'exact_match_{k}': v for k, v in exact_match_count.items()}\n",
    "    \n",
    "    return {\n",
    "        **{\n",
    "            \"size\": model_size,\n",
    "            \"lr\": lr,\n",
    "            \"blk\": blk,\n",
    "            \"epoch\": epoch,\n",
    "            \"head_frozen\": head_frozen\n",
    "        },\n",
    "        **similarity_score_stats,\n",
    "        **exact_match_stats,\n",
    "        **exact_match_count,\n",
    "    }\n",
    "\n",
    "def plot_exact_match(df, min_idx, max_idx):\n",
    "    ticks = range(min_idx, max_idx + 1)\n",
    "    plot_df = df[min_idx:max_idx+1]\n",
    "    fig, ax = plt.subplots(2, 1, sharex=True)\n",
    "    plot_df.plot(marker='*', ax=ax[0], xlabel = \"Exact match count\", ylabel=\"Frequency\", xticks=ticks)\n",
    "    np.log(plot_df).plot(marker='*', ax=ax[1], xlabel = \"Exact match count\", ylabel=\"Log of Frequency\", xticks=ticks)\n",
    "    ax[1].get_legend().remove()\n",
    "    fig.set_figwidth(5)\n",
    "    fig.set_figheight(5)\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33d0773-3793-4b4d-8e12-df479c4534a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this if you need to re-generate the metrics\n",
    "\n",
    "metrics_path = \"./metrics\"\n",
    "\n",
    "metrics_files = [f for f in os.listdir(metrics_path) if f.endswith(\".csv\")]\n",
    "\n",
    "files_info = [process_file(f) for f in tqdm(metrics_files, position=0, leave=True)]\n",
    "files_info = [f for f in files_info if f is not None]\n",
    "\n",
    "df = pd.DataFrame(files_info)\n",
    "df.to_csv(\"./agg_metrics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35521b44-6486-4ef1-9cfa-96b70905e14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./agg_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd78517b-6193-4507-8f56-3a8232c30a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze model size effect\n",
    "\n",
    "size_df = df.loc[\n",
    "    (df[\"lr\"] == 1e-05) & (\n",
    "        ((df[\"size\"] == \"gpt2\") & (df[\"epoch\"] == 19)) |\n",
    "        ((df[\"size\"] == \"gpt2-medium\") & (df[\"epoch\"] == 9)) |\n",
    "        ((df[\"size\"] == \"gpt2-large\") & (df[\"epoch\"] == 4) & (df[\"blk\"] == 1.0)) |\n",
    "        ((df[\"size\"] == \"gpt2-xl\") & (df[\"epoch\"] == 2))\n",
    "    )\n",
    "]\n",
    "print(size_df[[\"size\", \"mean_similarity_score\", \"50%_similarity_score\", \"mean_exact_match\", \"max_exact_match\"]].sort_values(\"mean_similarity_score\").to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc27ff9-2884-42d6-a42b-508d591862de",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_plot_df = pd.wide_to_long(size_df, \"exact_match_\", i=\"size\", j=\"count\")[\"exact_match_\"].reset_index(\n",
    "    level=[\"size\"]).pivot(\n",
    "    columns = \"size\", values = \"exact_match_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759311cc-adfc-4c6e-91b0-fcbb4ca214f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_exact_match(size_plot_df, 1, 15)\n",
    "plt.savefig(\"./plots/size.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b09d18c-c883-49db-8751-227ef7dece55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze frozen block effect\n",
    "\n",
    "frozen_df = df.loc[\n",
    "    ((df[\"size\"] == \"gpt2-large\") & (df[\"blk\"] == 1.0) & (df[\"lr\"] == 1e-05) & (df[\"epoch\"] == 4) & (df[\"head_frozen\"] == False)) |\n",
    "    ((df[\"blk\"] == 0.7) & (df[\"lr\"] == 5e-07) & (df[\"epoch\"] == 2) & (df[\"head_frozen\"] == True)) |\n",
    "    ((df[\"blk\"] == 0.4) & (df[\"lr\"] == 1e-06) & (df[\"epoch\"] == 3) & (df[\"head_frozen\"] == True)) |\n",
    "    ((df[\"blk\"] == 0.7) & (df[\"lr\"] == 5e-07) & (df[\"epoch\"] == 2) & (df[\"head_frozen\"] == False)) |\n",
    "    ((df[\"blk\"] == 0.4) & (df[\"lr\"] == 5e-07) & (df[\"epoch\"] == 2) & (df[\"head_frozen\"] == False)) |\n",
    "    ((df[\"blk\"] == 0.0) & (df[\"lr\"] == 1e-05) & (df[\"epoch\"] == 2) & (df[\"head_frozen\"] == False))\n",
    "]\n",
    "print(frozen_df[[\"blk\", \"head_frozen\", \"mean_similarity_score\", \"50%_similarity_score\", \"mean_exact_match\", \"max_exact_match\"]].sort_values(\"mean_similarity_score\").to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829e3060-9c40-4f47-b688-0255da536870",
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_plot_df = pd.wide_to_long(frozen_df, \"exact_match_\", i=[\"blk\", \"head_frozen\"], j=\"count\")[\"exact_match_\"].reset_index(\n",
    "    level=[\"blk\", \"head_frozen\"]).pivot(\n",
    "    columns = [\"blk\", \"head_frozen\"], values = \"exact_match_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddeda13-1434-444d-a7cd-101ac575e235",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_exact_match(frozen_plot_df, 1, 15)\n",
    "plt.savefig(\"./plots/frozen.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18adb17-fd42-4ddd-be21-e9ab812ecd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze different decoding methods\n",
    "\n",
    "greedy_df = process_file(\"metrics_model_gen_gpt2-large_5e-05_equal_dataset_50000_epoch_4.csv\", force=True)\n",
    "beam_search_df = process_file(\"metrics_model_gen_gpt2-large_equal_dataset_50000_beam_search_lr5e-05_epoch_4.csv\", force=True)\n",
    "temp_df = process_file(\"metrics_model_gen_gpt2-large_equal_dataset_50000_temperature_lr5e-05_epoch_4.csv\", force=True)\n",
    "top_p_df = process_file(\"metrics_model_gen_gpt2-large_equal_dataset_50000_top-p_lr5e-05_epoch_4.csv\", force=True)\n",
    "\n",
    "greedy_df[\"method\"] = \"greedy\"\n",
    "beam_search_df[\"method\"] = \"beam search (num_beam=8)\"\n",
    "temp_df[\"method\"] = \"random sampling (temp=0.85)\"\n",
    "top_p_df[\"method\"] = \"top p sampling (p=0.85)\"\n",
    "\n",
    "decode_df = pd.DataFrame([greedy_df, beam_search_df, temp_df, top_p_df]).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c545ad94-df49-47cd-99a6-4e1cac948edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(decode_df[[\"method\", \"mean_similarity_score\", \"50%_similarity_score\", \"mean_exact_match\", \"max_exact_match\"]].sort_values(\"mean_similarity_score\").to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af092e48-c0f2-4603-be4d-d63e09d565b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_plot_df = pd.wide_to_long(decode_df, \"exact_match_\", i=\"method\", j=\"count\")[\"exact_match_\"].reset_index(\n",
    "    level=[\"method\"]).pivot(\n",
    "    columns = \"method\", values = \"exact_match_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f05195-481b-4709-8aa5-826543554915",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_exact_match(decode_plot_df, 1, 20)\n",
    "plt.savefig(\"./plots/decode.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd44c4d-0b60-424a-bc93-d9a38eade389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze prompt length\n",
    "\n",
    "prompt_lengths = [20, 70, 100]\n",
    "length_df = pd.read_csv(\"./metrics/metrics_prompt_lengths.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006a67b3-f440-439c-87a5-6c059ea425d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "length_df[[f\"{length}_similarity_score\" for length in prompt_lengths] + [f\"{length}_exact_match\" for length in prompt_lengths]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7915eb05-ba35-464d-babe-1c00c5cfbd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = length_df[[f\"{length}_exact_match\" for length in prompt_lengths]].apply(pd.Series.value_counts).fillna(0)[:0:-1].cumsum()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec902fe-bfce-402e-9480-ff2aa0d968b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(counts).plot(marker='*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4144b2d8-1ca9-456c-b467-8fdbec55dc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the longest exact match that seems to persist across many different model generations\n",
    "\n",
    "df = pd.read_csv(\"./metrics/metrics_model_gen_gpt2-large_5e-05_equal_dataset_50000_epoch_4.csv\")\n",
    "print(list(df.loc[df[\"exact_match\"] == 54][\"text\"]))\n",
    "print(list(df.loc[df[\"exact_match\"] == 54][\"promptLength70_numBeams1\"]))\n",
    "print(list(df.loc[df[\"exact_match\"] == 54][\"original_sentence\"]))\n",
    "print(list(df.loc[df[\"exact_match\"] == 54][\"generated_sentence\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Finetune [conda env:Memorization-finetune]",
   "language": "python",
   "name": "conda-env-Memorization-finetune-finetune"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
