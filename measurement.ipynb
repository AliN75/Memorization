{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b746034-60cf-455e-b256-20ddee67836a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/anaseh_umass_edu/anaconda3/envs/test/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Import the libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import nltk\n",
    "import re\n",
    "import csv\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import GPT2Tokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, AutoConfig, GPTNeoForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import os\n",
    "import openai\n",
    "from re import search\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f087aada-7e56-4d26-b0a3-9b8390005f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1301a59d-d9e7-4c44-bbc9-32dce6a562d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95089e34-416a-468e-9869-8c2c207793c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/anaseh_umass_edu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbb34659-ddf6-47d4-b951-55b46a47047c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 718/718 [00:00<00:00, 161kB/s]\n",
      "Downloading (…)olve/main/vocab.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 3.93MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 3.63MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 1.36M/1.36M [00:00<00:00, 4.66MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Modify the tokenizer if needed.\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2-medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bde581fb-8b91-4e90-b5c9-e15c47c45557",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)\"pytorch_model.bin\";: 100%|██████████| 1.52G/1.52G [00:32<00:00, 47.1MB/s]\n",
      "Downloading (…)neration_config.json: 100%|██████████| 124/124 [00:00<00:00, 56.8kB/s]\n"
     ]
    }
   ],
   "source": [
    "# Change the config if needed.\n",
    "config = AutoConfig.from_pretrained(\"gpt2-medium\")\n",
    "\n",
    "# Change the tokenizer if needed.\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2-medium\", config=config, pad_token_id=tokenizer.eos_token_id).cuda()\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56668dc-d140-438b-88e2-5ee11a37810e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the path if needed\n",
    "model.load_state_dict(torch.load('gpt_2_test/checkpoint-100/pytorch_model.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15065684-f735-45c3-a32c-ef026a1b9685",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_similarity_check = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fe0d82b-5a6a-4589-a617-d2cf344bb81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_score(text1, text2):\n",
    "    \n",
    "    #Compute embedding for both lists\n",
    "    embeddings1 = model_similarity_check.encode(text1, convert_to_tensor=True)\n",
    "    embeddings2 = model_similarity_check.encode(text2, convert_to_tensor=True)\n",
    "    \n",
    "    #Compute cosine-similarities\n",
    "    cosine_scores = util.cos_sim(embeddings1, embeddings2)\n",
    "    \n",
    "    return cosine_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd558454-603a-46e6-8f33-c7c2327d26a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "If the decoding algorithm is one of the greedy search or beam search, the generated text might be repetitive. \n",
    "Hence, we wrote this function to check if the generated text is repetitive. If so, we will remove that sample.\n",
    "\"\"\"\n",
    "\n",
    "def has_repetition(generated_text, window_size=10):\n",
    "    \"\"\"\n",
    "    Determines if there is repetitive text in a generated text using a sliding window of the specified size.\n",
    "    Returns True if there is any repetition and False otherwise.\n",
    "    \"\"\"\n",
    "    window_start = 0\n",
    "    window_end = window_size\n",
    "    while window_end < len(generated_text):\n",
    "        window_text = generated_text[window_start:window_end]\n",
    "        if window_text in generated_text[window_end:]:\n",
    "            return True\n",
    "        window_start += 1\n",
    "        window_end += 1\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa60fbf-1cfb-41d3-99d1-36e5b9b2a4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We initiate a dictionary to save values for different lengths. For each length, we save the number of samples of that length and the sum of the scores. In the end, we can compute the average score for each length.\n",
    "\"\"\"\n",
    "\n",
    "results = {}\n",
    "for i in range(100):\n",
    "    results[str(i)] = [0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d36890c6-5fa6-4b0f-89f5-c99ec9a2e712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset\n",
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "728bedb6-d5d6-47a8-84f3-1ff83606dd04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;cs.CR&gt;:   An access control model called Zero...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;gr-qc&gt;:   Using quantum Riemannian geometry, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;gr-qc&gt;:   Noether's theorem identifies fundam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>&lt;stat.ME&gt;:   Multilevel models (mixed-effect m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text\n",
       "0           0  <cs.CR>:   An access control model called Zero...\n",
       "1           1  <gr-qc>:   Using quantum Riemannian geometry, ...\n",
       "2           2  <gr-qc>:   Noether's theorem identifies fundam...\n",
       "3           3  <stat.ME>:   Multilevel models (mixed-effect m..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138906d0-a67d-43e4-9631-64e06bf40168",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "flags = [1000, 4000, 8000, 15000, 27000]\n",
    "num_of_repetitive_samples = 0\n",
    "\n",
    "for i in range(len(df)):\n",
    "    \n",
    "    if i in flags:\n",
    "        print(i)\n",
    "\n",
    "    \n",
    "    # You can change the length to test different values.    \n",
    "    prompt = df['text'][i].split(\" \")[:50]\n",
    "    prompt = ' '.join(prompt)\n",
    "    init_sentences = nltk.sent_tokenize(prompt)\n",
    "    length = len(init_sentences)\n",
    "    input_ids = tokenizer(prompt, return_tensors='pt').to(device)\n",
    "    \n",
    "    # You can modify the max_length based on the prompt length.\n",
    "    temp_text = model.generate(**input_ids, max_length=150, num_beams = 6)\n",
    "    temp_text = tokenizer.decode(temp_text[0], skip_special_tokens=True)\n",
    "    \n",
    "   \n",
    "    sentences = nltk.sent_tokenize(temp_text)\n",
    "    final_text = sentences[length-1]\n",
    "    \n",
    "    if has_repetition(final_text):\n",
    "        #print(final_text)\n",
    "        num_of_repetitive_samples += 1\n",
    "        continue\n",
    "    \n",
    "    orig_sentences = nltk.sent_tokenize(df['text'][i])\n",
    "    score = similarity_score(orig_sentences[length-1], final_text)\n",
    "    diff = len(final_text.split(' ')) - len(init_sentences[length-1].split(\" \"))\n",
    "    \n",
    "    \n",
    "    results[str(diff)][0] += 1\n",
    "    results[str(diff)][1] += score[0].item()\n",
    "    #print(\"Score: \" + str(score))\n",
    "    #print(\"Diff: \" + str(diff))\n",
    "    #print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "52b29e83-24c1-4999-a758-d0847dba2da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(results)):\n",
    "    if results[str(i)][0] > 0:\n",
    "        results[str(i)][1] = results[str(i)][1]/results[str(i)][0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "98c7169c-5d30-444f-82be-6f46d87a0ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': [5, 0.8857958436012268], '1': [3, 0.9013360540072123], '2': [6, 0.722661112745603], '3': [4, 0.6346058398485184], '4': [7, 0.775366987500872], '5': [2, 0.6704206466674805], '6': [2, 0.48442715406417847], '7': [6, 0.803336888551712], '8': [4, 0.5602045580744743], '9': [0, 0], '10': [1, 0.8796998262405396], '11': [2, 0.6954313218593597], '12': [0, 0], '13': [3, 0.41146397590637207], '14': [2, 0.5290040820837021], '15': [3, 0.46533167362213135], '16': [2, 0.370731383562088], '17': [4, 0.5017414093017578], '18': [1, 0.36304786801338196], '19': [2, 0.4280588924884796], '20': [1, 0.3395509123802185], '21': [1, 0.33076173067092896], '22': [1, 0.6550519466400146], '23': [0, 0], '24': [0, 0], '25': [0, 0], '26': [0, 0], '27': [0, 0], '28': [0, 0], '29': [0, 0], '30': [0, 0], '31': [0, 0], '32': [0, 0], '33': [0, 0], '34': [0, 0], '35': [0, 0], '36': [0, 0], '37': [0, 0], '38': [0, 0], '39': [0, 0], '40': [0, 0], '41': [0, 0], '42': [0, 0], '43': [0, 0], '44': [0, 0], '45': [0, 0], '46': [0, 0], '47': [0, 0], '48': [0, 0], '49': [0, 0], '50': [0, 0], '51': [0, 0], '52': [0, 0], '53': [0, 0], '54': [0, 0], '55': [0, 0], '56': [0, 0], '57': [0, 0], '58': [0, 0], '59': [0, 0], '60': [0, 0], '61': [0, 0], '62': [0, 0], '63': [0, 0], '64': [0, 0], '65': [0, 0], '66': [0, 0], '67': [0, 0], '68': [0, 0], '69': [0, 0], '70': [0, 0], '71': [0, 0], '72': [0, 0], '73': [0, 0], '74': [0, 0], '75': [0, 0], '76': [0, 0], '77': [0, 0], '78': [0, 0], '79': [0, 0], '80': [0, 0], '81': [0, 0], '82': [0, 0], '83': [0, 0], '84': [0, 0], '85': [0, 0], '86': [0, 0], '87': [0, 0], '88': [0, 0], '89': [0, 0], '90': [0, 0], '91': [0, 0], '92': [0, 0], '93': [0, 0], '94': [0, 0], '95': [0, 0], '96': [0, 0], '97': [0, 0], '98': [0, 0], '99': [0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3701ad0b-9e37-47ae-9ccd-b08811d7c30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame.from_dict(results, orient='index', columns=['Number', 'Mean'])\n",
    "\n",
    "# Set the name of saved file in the same format of the fine-tuned model name\n",
    "df_results.to_csv('test.csv', index_label='key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19e67e3-7950-45c3-8fcc-d3f07f80f714",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (anaconda3-test)",
   "language": "python",
   "name": "conda-env-anaconda3-test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
